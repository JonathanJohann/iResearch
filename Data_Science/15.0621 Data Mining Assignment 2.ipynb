{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining 15.0621 Homework Assignment 2\n",
    "## Questions 6.1, 7.3, 8.2, 9.3\n",
    "## By: Jonathan Johannemann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt,warnings,random,sklearn\n",
    "random.seed(11152016) #Today's Date\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CAT.MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   LSTAT  MEDV  CAT.MEDV  \n",
       "0   4.98  24.0         0  \n",
       "1   9.14  21.6         0  \n",
       "2   4.03  34.7         1  \n",
       "3   2.94  33.4         1  \n",
       "4   5.33  36.2         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bostonhousing = pd.read_csv('BostonHousing.csv',sep=',',header=0)\n",
    "bostonhousing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.1 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data should be partitioned into training and validation sets because it allows the researcher to receive feedback on his or her model without testing on the true, held out data. The training set is for the model to be trained on. The validation set is for the researcher to test the ability of his or her model. A researcher should never introduce datapoints from the validation set into the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.1 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  -28.8106825064\n",
      "CRIM coefficient:  -0.260724411231\n",
      "CHAS coefficient:  3.76303705211\n",
      "RM coefficient:  8.27817981154\n",
      "\n",
      "Equation: \n",
      "-28.8106825064  +  -0.260724411231 CRIM +  3.76303705211 CHAS +  8.27817981154 RM = MEDV\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(bostonhousing[['CRIM','CHAS','RM']],bostonhousing['MEDV'])\n",
    "print \"Intercept: \",model.intercept_\n",
    "print \"CRIM coefficient: \",model.coef_[0]\n",
    "print \"CHAS coefficient: \",model.coef_[1]\n",
    "print \"RM coefficient: \",model.coef_[2]\n",
    "print \"\\nEquation: \\n\",model.intercept_, \" + \",model.coef_[0],\"CRIM + \",model.coef_[1],\"CHAS + \",model.coef_[2],\"RM = MEDV\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.1 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted price is:  20.8323239217\n"
     ]
    }
   ],
   "source": [
    "query = pd.DataFrame([['0.1','0','6']],columns=['CRIM','CHAS','RM'])\n",
    "print \"The predicted price is: \",model.predict(query)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error with respect to the closest value is: 2.06767607827\n"
     ]
    }
   ],
   "source": [
    "tmp = bostonhousing[['CRIM','CHAS','RM']]\n",
    "query_vals = query.values[0].astype('Float64')\n",
    "index_closest = np.abs(tmp.apply(lambda x: x-query_vals,axis=1).sum(axis=1)).ix[np.abs(tmp.apply(lambda x: x-query_vals,axis=1).sum(axis=1))==np.abs(tmp.apply(lambda x: x-query_vals,axis=1).sum(axis=1)).min()].index[0]\n",
    "print \"The error with respect to the closest value is:\", np.abs(bostonhousing.MEDV.ix[index_closest]-model.predict(query)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.1 (d) i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          INDUS       NOX       TAX\n",
      "INDUS  1.000000  0.763651  0.720760\n",
      "NOX    0.763651  1.000000  0.668023\n",
      "TAX    0.720760  0.668023  1.000000\n"
     ]
    }
   ],
   "source": [
    "corr_mat = bostonhousing[['INDUS','NOX','TAX']].corr()\n",
    "print corr_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indus is the proportion of nonretail business acres per town.\n",
    "Nox is nitric oxide concentration.\n",
    "Tax is full-value property-tax rate per $10,000.\n",
    "The potential relationsnip here is that businesses create more nitric oxide and result in higher taxed property. Therefore, there is likely a causal relationship from INDUS to NOX and TAX. While it is not east ro 100% confirm this, it appears to be a likely scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.1 (d) ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Looking at:  CRIM\n",
      "RAD  :  0.625505145263\n",
      "========================================\n",
      "Looking at:  ZN\n",
      "DIS  :  0.664408222762\n",
      "========================================\n",
      "Looking at:  INDUS\n",
      "NOX  :  0.763651446921\n",
      "AGE  :  0.644778511355\n",
      "DIS  :  -0.708026988743\n",
      "TAX  :  0.720760179952\n",
      "LSTAT  :  0.603799716477\n",
      "========================================\n",
      "Looking at:  NOX\n",
      "INDUS  :  0.763651446921\n",
      "AGE  :  0.731470103786\n",
      "DIS  :  -0.769230113226\n",
      "RAD  :  0.611440563486\n",
      "TAX  :  0.668023200403\n",
      "========================================\n",
      "Looking at:  RM\n",
      "LSTAT  :  -0.613808271866\n",
      "MEDV  :  0.695359947072\n",
      "CAT.MEDV  :  0.641265408301\n",
      "========================================\n",
      "Looking at:  AGE\n",
      "INDUS  :  0.644778511355\n",
      "NOX  :  0.731470103786\n",
      "DIS  :  -0.747880540869\n",
      "LSTAT  :  0.602338528726\n",
      "========================================\n",
      "Looking at:  DIS\n",
      "ZN  :  0.664408222762\n",
      "INDUS  :  -0.708026988743\n",
      "NOX  :  -0.769230113226\n",
      "AGE  :  -0.747880540869\n",
      "========================================\n",
      "Looking at:  RAD\n",
      "CRIM  :  0.625505145263\n",
      "NOX  :  0.611440563486\n",
      "TAX  :  0.910228188533\n",
      "========================================\n",
      "Looking at:  TAX\n",
      "INDUS  :  0.720760179952\n",
      "NOX  :  0.668023200403\n",
      "RAD  :  0.910228188533\n",
      "========================================\n",
      "Looking at:  LSTAT\n",
      "INDUS  :  0.603799716477\n",
      "RM  :  -0.613808271866\n",
      "AGE  :  0.602338528726\n",
      "MEDV  :  -0.737662726174\n",
      "========================================\n",
      "Looking at:  MEDV\n",
      "RM  :  0.695359947072\n",
      "LSTAT  :  -0.737662726174\n",
      "CAT.MEDV  :  0.789788766697\n",
      "========================================\n",
      "Looking at:  CAT.MEDV\n",
      "RM  :  0.641265408301\n",
      "MEDV  :  0.789788766697\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "corr_mat = bostonhousing.corr()\n",
    "corr_mat.values[[np.arange(len(corr_mat))]*2]=0\n",
    "corr_mat = corr_mat[np.abs(corr_mat)>0.6].fillna(0).reset_index()\n",
    "\n",
    "for col in corr_mat.columns.values[1:]:\n",
    "    if len(corr_mat[corr_mat[col]!=0][col].index)>0:\n",
    "        print \"=\"*40\n",
    "        print \"Looking at: \",col\n",
    "        for i in corr_mat[corr_mat[col]!=0][col].index:\n",
    "            print corr_mat['index'][i],\" : \",corr_mat[corr_mat[col]!=0][col][i]\n",
    "print \"=\"*40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAT.MEDV is based off of MEDV so we need to remove that. As discussed before, it seems like INDUS may be influencing NOX and TAX a lot which causes the high correlation. Therefore, we shall remove NOX and TAX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.1 (d) iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of models we need to test:  10\n",
      "['CRIM' 'ZN' 'LSTAT' 'AGE']\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "predictor_columns = list(set(bostonhousing.columns.values)-set(['MEDV','CAT.MEDV','NOX','TAX']))\n",
    "\n",
    "vars_for_model = []\n",
    "sum_val = 0\n",
    "\n",
    "model = sklearn.linear_model.Lasso().fit(bostonhousing[predictor_columns],bostonhousing.MEDV)\n",
    "\n",
    "for i in range(len(model.coef_[np.abs(model.coef_)>0]),10):\n",
    "    sum_val+= len(list(combinations(predictor_columns,i)))\n",
    "    vars_for_model.append(np.array(list(combinations(predictor_columns,i)))[0])\n",
    "print \"The number of models we need to test: \",sum_val\n",
    "print np.array(list(combinations(predictor_columns,4))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>65.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.14</td>\n",
       "      <td>78.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.33</td>\n",
       "      <td>54.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.21</td>\n",
       "      <td>58.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.43</td>\n",
       "      <td>66.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>19.15</td>\n",
       "      <td>96.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>29.93</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>17.10</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.22489</td>\n",
       "      <td>12.5</td>\n",
       "      <td>20.45</td>\n",
       "      <td>94.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11747</td>\n",
       "      <td>12.5</td>\n",
       "      <td>13.27</td>\n",
       "      <td>82.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.09378</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.71</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>61.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.26</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.47</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.05393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.58</td>\n",
       "      <td>29.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.67</td>\n",
       "      <td>81.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.69</td>\n",
       "      <td>36.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.28</td>\n",
       "      <td>69.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.25179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.02</td>\n",
       "      <td>98.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.85204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.83</td>\n",
       "      <td>89.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.72</td>\n",
       "      <td>91.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.98843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.88</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.75026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.30</td>\n",
       "      <td>94.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.84054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.51</td>\n",
       "      <td>85.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.67191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>90.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.95577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.28</td>\n",
       "      <td>88.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.77299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.80</td>\n",
       "      <td>94.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.98</td>\n",
       "      <td>87.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4.87141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.68</td>\n",
       "      <td>93.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.91</td>\n",
       "      <td>97.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>10.23300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.03</td>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>14.33370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.11</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5.82401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.74</td>\n",
       "      <td>64.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5.70818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.74</td>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>5.73116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.01</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2.81838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.42</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2.37857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.34</td>\n",
       "      <td>41.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3.67367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.58</td>\n",
       "      <td>51.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>5.69175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.98</td>\n",
       "      <td>79.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4.83567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.45</td>\n",
       "      <td>53.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.15086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.06</td>\n",
       "      <td>92.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.18337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.97</td>\n",
       "      <td>98.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.20746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.68</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.07</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.11132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.35</td>\n",
       "      <td>83.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.17331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.01</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.27957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.59</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.17899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.60</td>\n",
       "      <td>28.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.28960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.14</td>\n",
       "      <td>72.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.26838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.10</td>\n",
       "      <td>70.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.23912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.92</td>\n",
       "      <td>65.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.17783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.10</td>\n",
       "      <td>73.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>79.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>69.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.08</td>\n",
       "      <td>76.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>89.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  LSTAT    AGE\n",
       "0     0.00632  18.0   4.98   65.2\n",
       "1     0.02731   0.0   9.14   78.9\n",
       "2     0.02729   0.0   4.03   61.1\n",
       "3     0.03237   0.0   2.94   45.8\n",
       "4     0.06905   0.0   5.33   54.2\n",
       "5     0.02985   0.0   5.21   58.7\n",
       "6     0.08829  12.5  12.43   66.6\n",
       "7     0.14455  12.5  19.15   96.1\n",
       "8     0.21124  12.5  29.93  100.0\n",
       "9     0.17004  12.5  17.10   85.9\n",
       "10    0.22489  12.5  20.45   94.3\n",
       "11    0.11747  12.5  13.27   82.9\n",
       "12    0.09378  12.5  15.71   39.0\n",
       "13    0.62976   0.0   8.26   61.8\n",
       "14    0.63796   0.0  10.26   84.5\n",
       "15    0.62739   0.0   8.47   56.5\n",
       "16    1.05393   0.0   6.58   29.3\n",
       "17    0.78420   0.0  14.67   81.7\n",
       "18    0.80271   0.0  11.69   36.6\n",
       "19    0.72580   0.0  11.28   69.5\n",
       "20    1.25179   0.0  21.02   98.1\n",
       "21    0.85204   0.0  13.83   89.2\n",
       "22    1.23247   0.0  18.72   91.7\n",
       "23    0.98843   0.0  19.88  100.0\n",
       "24    0.75026   0.0  16.30   94.1\n",
       "25    0.84054   0.0  16.51   85.7\n",
       "26    0.67191   0.0  14.81   90.3\n",
       "27    0.95577   0.0  17.28   88.8\n",
       "28    0.77299   0.0  12.80   94.4\n",
       "29    1.00245   0.0  11.98   87.3\n",
       "..        ...   ...    ...    ...\n",
       "476   4.87141   0.0  18.68   93.6\n",
       "477  15.02340   0.0  24.91   97.3\n",
       "478  10.23300   0.0  18.03   96.7\n",
       "479  14.33370   0.0  13.11   88.0\n",
       "480   5.82401   0.0  10.74   64.7\n",
       "481   5.70818   0.0   7.74   74.9\n",
       "482   5.73116   0.0   7.01   77.0\n",
       "483   2.81838   0.0  10.42   40.3\n",
       "484   2.37857   0.0  13.34   41.9\n",
       "485   3.67367   0.0  10.58   51.9\n",
       "486   5.69175   0.0  14.98   79.8\n",
       "487   4.83567   0.0  11.45   53.2\n",
       "488   0.15086   0.0  18.06   92.7\n",
       "489   0.18337   0.0  23.97   98.3\n",
       "490   0.20746   0.0  29.68   98.0\n",
       "491   0.10574   0.0  18.07   98.8\n",
       "492   0.11132   0.0  13.35   83.5\n",
       "493   0.17331   0.0  12.01   54.0\n",
       "494   0.27957   0.0  13.59   42.6\n",
       "495   0.17899   0.0  17.60   28.8\n",
       "496   0.28960   0.0  21.14   72.9\n",
       "497   0.26838   0.0  14.10   70.6\n",
       "498   0.23912   0.0  12.92   65.3\n",
       "499   0.17783   0.0  15.10   73.5\n",
       "500   0.22438   0.0  14.33   79.7\n",
       "501   0.06263   0.0   9.67   69.1\n",
       "502   0.04527   0.0   9.08   76.7\n",
       "503   0.06076   0.0   5.64   91.0\n",
       "504   0.10959   0.0   6.48   89.3\n",
       "505   0.04741   0.0   7.88   80.8\n",
       "\n",
       "[506 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bostonhousing[np.array(list(combinations(predictor_columns,4))[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a heuristic for determining the minimum number of variables to find the best model, I used the Lasso to set the lower bound. The Lasso is capable of reducing variable coefficients to 0 if they have no predictive power and so I will use the number of non-zero weights as a lower bound for searching for the best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 1 model by R^2 measure includes the variables:\n",
      "('CRIM', 'ZN', 'LSTAT', 'AGE', 'CHAS', 'RM', 'INDUS', 'PTRATIO', 'DIS')\n",
      "The training set score is:  0.717762873428\n",
      "\n",
      "Top 2 model by R^2 measure includes the variables:\n",
      "('ZN', 'LSTAT', 'AGE', 'RAD', 'CHAS', 'RM', 'INDUS', 'PTRATIO', 'DIS')\n",
      "The training set score is:  0.715333941469\n",
      "\n",
      "Top 3 model by R^2 measure includes the variables:\n",
      "('ZN', 'LSTAT', 'AGE', 'CHAS', 'RM', 'INDUS', 'PTRATIO', 'DIS')\n",
      "The training set score is:  0.715135771826\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.LinearRegression()\n",
    "X,Xt,y,yt = sklearn.cross_validation.train_test_split(bostonhousing[predictor_columns],bostonhousing.MEDV,test_size=0.2)\n",
    "score_arr = []\n",
    "all_models = []\n",
    "for i in range(1,10):\n",
    "    vars_for_model = list(combinations(predictor_columns,i))\n",
    "    all_models+=vars_for_model\n",
    "    for preds in vars_for_model:\n",
    "        preds = np.array(preds)\n",
    "        score_arr.append(model.fit(X[preds],y).score(X[preds],y))\n",
    "vals_zip = sorted(zip(all_models,score_arr),key = lambda t: t[1],reverse=True)\n",
    "for i in range(3):\n",
    "    print \"\\nTop %s model by R^2 measure includes the variables:\\n\" % (i+1),vals_zip[i][0]\n",
    "    print \"The training set score is: \",model.fit(X[np.array(vals_zip[i][0])],y).score(X[np.array(vals_zip[i][0])],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 1 model includes the variables:\n",
      "('CRIM', 'ZN', 'LSTAT', 'AGE', 'CHAS', 'RM', 'INDUS', 'PTRATIO', 'DIS')\n",
      "The cross validation score is:  0.685465009418\n",
      "\n",
      "Top 2 model includes the variables:\n",
      "('ZN', 'LSTAT', 'AGE', 'RAD', 'CHAS', 'RM', 'INDUS', 'PTRATIO', 'DIS')\n",
      "The cross validation score is:  0.667540808017\n",
      "\n",
      "Top 3 model includes the variables:\n",
      "('ZN', 'LSTAT', 'AGE', 'CHAS', 'RM', 'INDUS', 'PTRATIO', 'DIS')\n",
      "The cross validation score is:  0.667421492589\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print \"\\nTop %s model includes the variables:\\n\" % (i+1),vals_zip[i][0]\n",
    "    print \"The cross validation score is: \",model.fit(X[np.array(vals_zip[i][0])],y).score(Xt[np.array(vals_zip[i][0])],yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the problem says to choose the top three models but it does not say what it's based on. So from what I can see, it looks like there should be a 20% cross validation set and then an 80% training set. I am assuming that the best model should be determined in terms of accuracy on the training set data via R^2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7.3 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CAT.MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   LSTAT  MEDV  CAT.MEDV  \n",
       "0   4.98  24.0         0  \n",
       "1   9.14  21.6         0  \n",
       "2   4.03  34.7         1  \n",
       "3   2.94  33.4         1  \n",
       "4   5.33  36.2         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bostonhousing = pd.read_csv('BostonHousing.csv',sep=',',header=0)\n",
    "bostonhousing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
      "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
      "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
      "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
      "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
      "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
      "\n",
      "        DIS       RAD       TAX   PTRATIO     LSTAT  MEDV  CAT.MEDV  \n",
      "0  0.140214 -0.982843 -0.666608 -1.459000 -1.075562  24.0         0  \n",
      "1  0.557160 -0.867883 -0.987329 -0.303094 -0.492439  21.6         0  \n",
      "2  0.557160 -0.867883 -0.987329 -0.303094 -1.208727  34.7         1  \n",
      "3  1.077737 -0.752922 -1.106115  0.113032 -1.361517  33.4         1  \n",
      "4  1.077737 -0.752922 -1.106115  0.113032 -1.026501  36.2         1  \n"
     ]
    }
   ],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "columns = list(set(bostonhousing.columns.values)-set(['MEDV','CAT.MEDV']))\n",
    "for col in columns:\n",
    "    bostonhousing[col] = scaler.fit_transform(bostonhousing[col])\n",
    "\n",
    "print bostonhousing.head()\n",
    "\n",
    "X,Xt,y,yt = sklearn.cross_validation.train_test_split(bostonhousing[columns],bostonhousing.MEDV,test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  1 , R^2 value is: 0.688810576034\n",
      "For k =  2 , R^2 value is: 0.731833948465\n",
      "For k =  3 , R^2 value is: 0.704432166734\n",
      "For k =  4 , R^2 value is: 0.710606592954\n",
      "For k =  5 , R^2 value is: 0.700079447868\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    knn_model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=i)\n",
    "    knn_model.fit(X,y)\n",
    "    print \"For k = \",i,\", R^2 value is:\",knn_model.score(Xt,yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 12 variables, it looks like k = 2 has the best performance with respect to R^2 value. This means that the prediction is based on the bucket/leaf that is indicated from the closest 2 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 7.3 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 2 , predicted value is: [ 10.3]\n"
     ]
    }
   ],
   "source": [
    "query = pd.DataFrame([[0.2,0,7,0,0.538,6,62,4.7,4,307,21,10]],columns=list(bostonhousing.columns.values[:12]))\n",
    "knn_model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=2)\n",
    "knn_model.fit(X,y)\n",
    "print \"For k =\",2,\", predicted value is:\",knn_model.predict(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7.3 (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation error is still optimistic because we tweak the original model on this data. So, we get an idea of what works and does not work. In an indirect way, we are getting a feel for what works and does not work in the validation set. We, of course, do not get this chance for the test set which is suppose to be our final evaluation. Hence, over time, as we make changes to the model that was trained on the training set based on our evaluation of the validation set, we start to introduce an almost look-ahead bias. This essentially means that we are looking at data and coming up with a model that will of course do well on this set because we have tried multiple things that work and do not work which is something that is not allowed for the test set. Thus, the error for the validation set ends up being overly optimistic because we've taken steps to improve the error on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7.3 (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CRIM        ZN     INDUS  CHAS       NOX        RM       AGE       DIS  \\\n",
      "0 -0.419782  0.284830 -1.287909     0 -0.144217  0.413672 -0.120013  0.140214   \n",
      "1 -0.417339 -0.487722 -0.593381     0 -0.740262  0.194274  0.367166  0.557160   \n",
      "2 -0.417342 -0.487722 -0.593381     0 -0.740262  1.282714 -0.265812  0.557160   \n",
      "3 -0.416750 -0.487722 -1.306878     0 -0.835284  1.016303 -0.809889  1.077737   \n",
      "4 -0.412482 -0.487722 -1.306878     0 -0.835284  1.228577 -0.511180  1.077737   \n",
      "\n",
      "        RAD       TAX   PTRATIO     LSTAT  MEDV  CAT.MEDV  \n",
      "0 -0.982843 -0.666608 -1.459000 -1.075562  24.0         0  \n",
      "1 -0.867883 -0.987329 -0.303094 -0.492439  21.6         0  \n",
      "2 -0.867883 -0.987329 -0.303094 -1.208727  34.7         1  \n",
      "3 -0.752922 -1.106115  0.113032 -1.361517  33.4         1  \n",
      "4 -0.752922 -1.106115  0.113032 -1.026501  36.2         1   \n",
      "\n",
      "For k =  1 , R^2 value is: 0.710915183285\n",
      "For k =  2 , R^2 value is: 0.745797512212\n",
      "For k =  3 , R^2 value is: 0.714353267799\n",
      "For k =  4 , R^2 value is: 0.713726693547\n",
      "For k =  5 , R^2 value is: 0.699522682614\n",
      "\n",
      "For k = 2 , predicted value is: [ 13.76]\n"
     ]
    }
   ],
   "source": [
    "bostonhousing = pd.read_csv('BostonHousing.csv',sep=',',header=0)\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "continuous_columns = list(set(bostonhousing.columns.values)-set(['CHAS','MEDV','CAT.MEDV',]))\n",
    "for col in continuous_columns:\n",
    "    bostonhousing[col] = scaler.fit_transform(bostonhousing[col])\n",
    "\n",
    "print bostonhousing.head(),\"\\n\"\n",
    "\n",
    "X,Xt,y,yt = sklearn.cross_validation.train_test_split(bostonhousing[columns],bostonhousing.MEDV,test_size=0.4)\n",
    "\n",
    "for i in range(1,6):\n",
    "    knn_model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=i)\n",
    "    knn_model = knn_model.fit(X,y)\n",
    "    print \"For k = \",i,\", R^2 value is:\",knn_model.score(Xt,yt)\n",
    "    \n",
    "print \"\\nFor k =\",2,\", predicted value is:\",knn_model.predict(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 7.3 (e)\n",
    "The disadvantage of using the k-NN prediction is that k-NN suffers already from the curse of dimensionality. The way k-NN makes regression predictions is a weighted average of the k nearest neighbors. However, in our model above, we have incorporated 12 predictors. So, already, there is no guarantee that there are always going to be close datapoints that are adequately capable of providing informative contributions to k-NN's prediction process. Also, even though we've made some improvement to normalize the data, k-NN is nonparametric and so it cannot tell when one variable has more impact than another. CRIM may be a huge factor and the a significant difference in value may drive huge changes in MEDV. However, if multiple of the other less significant factors are grouped close together, k-NN may incorrectly make the assumption that the datapoints are very similar in regression outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOUR_I_R</th>\n",
       "      <th>ALCHL_I</th>\n",
       "      <th>ALIGN_I</th>\n",
       "      <th>STRATUM_R</th>\n",
       "      <th>WRK_ZONE</th>\n",
       "      <th>WKDY_I_R</th>\n",
       "      <th>INT_HWY</th>\n",
       "      <th>LGTCON_I_R</th>\n",
       "      <th>MANCOL_I_R</th>\n",
       "      <th>PED_ACC_R</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAF_CON_R</th>\n",
       "      <th>TRAF_WAY</th>\n",
       "      <th>VEH_INVL</th>\n",
       "      <th>WEATHER_R</th>\n",
       "      <th>INJURY_CRASH</th>\n",
       "      <th>NO_INJ_I</th>\n",
       "      <th>PRPTYDMG_CRASH</th>\n",
       "      <th>FATALITIES</th>\n",
       "      <th>MAX_SEV_IR</th>\n",
       "      <th>INJURY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HOUR_I_R  ALCHL_I  ALIGN_I  STRATUM_R  WRK_ZONE  WKDY_I_R  INT_HWY  \\\n",
       "0         0        2        2          1         0         1        0   \n",
       "1         1        2        1          0         0         1        1   \n",
       "2         1        2        1          0         0         1        0   \n",
       "3         1        2        1          1         0         0        0   \n",
       "4         1        1        1          0         0         1        0   \n",
       "\n",
       "   LGTCON_I_R  MANCOL_I_R  PED_ACC_R   ...    TRAF_CON_R  TRAF_WAY  VEH_INVL  \\\n",
       "0           3           0          0   ...             0         3         1   \n",
       "1           3           2          0   ...             0         3         2   \n",
       "2           3           2          0   ...             1         2         2   \n",
       "3           3           2          0   ...             1         2         2   \n",
       "4           3           2          0   ...             0         2         3   \n",
       "\n",
       "   WEATHER_R  INJURY_CRASH  NO_INJ_I  PRPTYDMG_CRASH  FATALITIES  MAX_SEV_IR  \\\n",
       "0          1             1         1               0           0           1   \n",
       "1          2             0         0               1           0           0   \n",
       "2          2             0         0               1           0           0   \n",
       "3          1             0         0               1           0           0   \n",
       "4          1             0         0               1           0           0   \n",
       "\n",
       "   INJURY  \n",
       "0    True  \n",
       "1   False  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents = pd.read_csv('Accidents.csv',sep=',',header=0)\n",
    "accidents['INJURY'] = accidents.MAX_SEV_IR.apply(lambda x: x>0)\n",
    "accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of injury given crash:  0.508783159093\n"
     ]
    }
   ],
   "source": [
    "print \"Probability of injury given crash: \",len(accidents[accidents.INJURY==True])/float(len(accidents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the probability is over 50%, without further knowledge we assume that there is an injury."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (b) i.    NEEDS TO BE LOOKED AT AGAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEATHER_R</th>\n",
       "      <th>TRAF_CON_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.583333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.651339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       WEATHER_R  TRAF_CON_R\n",
       "count  12.000000   12.000000\n",
       "mean    1.583333    0.333333\n",
       "std     0.514929    0.651339\n",
       "min     1.000000    0.000000\n",
       "25%     1.000000    0.000000\n",
       "50%     2.000000    0.000000\n",
       "75%     2.000000    0.250000\n",
       "max     2.000000    2.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q82bi = accidents[['WEATHER_R','TRAF_CON_R','INJURY']].head(12)\n",
    "q82bi.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a preliminary look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xcc84cf8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA58AAAF2CAYAAADpxSwfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nik8AAABGp/gEAABgdIpPAAAARvf/A7Am7GTqGQlZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xce186d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "q82bi.WEATHER_R.value_counts('INJURY').plot(kind='bar',title='WEATHER_R vs. INJURY',ax=axs[0],figsize=(16,6))\n",
    "q82bi.TRAF_CON_R.value_counts('INJURY').plot(kind='bar',title='TRAF_CON_R vs. INJURY',ax=axs[1],figsize=(16,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (b) ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For WEATHER_R: 1 and TRAF_CON_R: 0,  we get:  0.503111033214\n",
      "For WEATHER_R: 1 and TRAF_CON_R: 1,  we get:  0.553423927525\n",
      "For WEATHER_R: 1 and TRAF_CON_R: 2,  we get:  0.531550068587\n",
      "For WEATHER_R: 2 and TRAF_CON_R: 0,  we get:  0.443616253907\n",
      "For WEATHER_R: 2 and TRAF_CON_R: 1,  we get:  0.500894454383\n",
      "For WEATHER_R: 2 and TRAF_CON_R: 2,  we get:  0.430294906166\n"
     ]
    }
   ],
   "source": [
    "injuries = accidents[accidents.INJURY==True]\n",
    "prob_df = np.zeros((12,3))\n",
    "count = 0\n",
    "for val1 in sorted(pd.unique(injuries['WEATHER_R'])):\n",
    "    weather_adjusted = injuries[injuries.WEATHER_R==val1]\n",
    "    weather_adjusted2 = accidents[accidents.WEATHER_R==val1]\n",
    "    for val2 in sorted(pd.unique(injuries['TRAF_CON_R'])):\n",
    "        traf_adjusted = weather_adjusted[weather_adjusted.TRAF_CON_R==val2]\n",
    "        traf_adjusted2 = weather_adjusted2[weather_adjusted2.TRAF_CON_R==val2]\n",
    "        print \"For WEATHER_R: %s and TRAF_CON_R: %s,\" % (val1,val2),\" we get: \",len(traf_adjusted)/float(len(traf_adjusted2)) \n",
    "        prob_df[count][2] = (len(traf_adjusted)/float(len(traf_adjusted2)))\n",
    "        prob_df[count][1] = val2\n",
    "        prob_df[count][0] = val1\n",
    "        count+=1\n",
    "prob_df = pd.DataFrame(prob_df,columns=['WEATHER_R','TRAF_CON_R','INJURY_PROB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we make these predictions based on the bayesian values on the entire table or just the 12?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (b) iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WEATHER_R  TRAF_CON_R INJURY  INJURY_PROB\n",
      "0          1           0   True     0.503111\n",
      "1          2           0  False     0.443616\n",
      "2          2           1  False     0.500894\n",
      "3          1           1  False     0.553424\n",
      "4          1           0  False     0.503111\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.merge(q82bi,prob_df,on=['WEATHER_R','TRAF_CON_R'],how='left')\n",
    "print new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INJURY Prediction\n",
      "0    True       True\n",
      "1   False      False\n",
      "2   False       True\n",
      "3   False       True\n",
      "4   False       True\n",
      "5    True      False\n",
      "6   False      False\n",
      "7    True       True\n",
      "8   False      False\n",
      "9   False      False\n",
      "10  False      False\n",
      "11  False       True \n",
      "\n",
      "Confusion Matrix: \n",
      "[[5 4]\n",
      " [1 2]]\n",
      "Accuracy:  0.583333333333\n",
      "F1 Score:  0.666666666667\n"
     ]
    }
   ],
   "source": [
    "new_df['Prediction'] = new_df.INJURY_PROB.apply(lambda x: x>0.50)\n",
    "print new_df[['INJURY','Prediction']],\"\\n\"\n",
    "conf_mat = sklearn.metrics.confusion_matrix(new_df.INJURY,new_df.Prediction)\n",
    "print \"Confusion Matrix: \\n\",conf_mat\n",
    "print \"Accuracy: \",(conf_mat[0][0]+conf_mat[1][1])/float(12)\n",
    "print \"F1 Score: \", (2*conf_mat[0][0])/float(2*conf_mat[0][0]+conf_mat[1][0]+conf_mat[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHAT ARE VALUE LABELS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (b) iv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEATHER_R = 1 injury probability:  0.872984810363\n",
      "TRAF_CON_R = 1 injury probability:  0.219644021992\n",
      "Multiply these two to get the naive Bayes conditional probability for given both: 0.191745894886\n"
     ]
    }
   ],
   "source": [
    "weather_probability = len(injuries[injuries.WEATHER_R==1])/float(len(injuries))\n",
    "traf_con_probability = len(injuries[injuries.TRAF_CON_R==1])/float(len(injuries))\n",
    "print \"WEATHER_R = 1 injury probability: \",weather_probability\n",
    "print \"TRAF_CON_R = 1 injury probability: \",traf_con_probability\n",
    "print \"Multiply these two to get the naive Bayes conditional probability for given both:\", weather_probability*traf_con_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOUBLE CHECK TO MAKE SURE THIS IS BEING DONE RIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (b) v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy value is:  0.872984810363\n"
     ]
    }
   ],
   "source": [
    "gnb = sklearn.naive_bayes.GaussianNB()\n",
    "gnb.fit(accidents[['WEATHER_R','TRAF_CON_R']],accidents['INJURY'])\n",
    "print \"The mean accuracy value is: \",gnb.score(injuries[['WEATHER_R','TRAF_CON_R']],injuries['INJURY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (c) i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#is this a reiteration of the first question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (c) ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (c) iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (c) iv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (c) v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2 (c) vi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.3 (a) i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿Id</th>\n",
       "      <th>Model</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>...</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>Power_Steering</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Mistlamps</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Backseat_Divider</th>\n",
       "      <th>Metallic_Rim</th>\n",
       "      <th>Radio_cassette</th>\n",
       "      <th>Tow_Bar</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>72937</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2002</td>\n",
       "      <td>41711</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>48000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>38500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ï»¿Id                                           Model  Price  Age_08_04  \\\n",
       "0    1   TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13500         23   \n",
       "1    2   TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13750         23   \n",
       "2    3  Â TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13950         24   \n",
       "3    4   TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  14950         26   \n",
       "4    5     TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors  13750         30   \n",
       "\n",
       "   Mfg_Month  Mfg_Year     KM Fuel_Type  HP  Met_Color     ...      \\\n",
       "0         10      2002  46986    Diesel  90          1     ...       \n",
       "1         10      2002  72937    Diesel  90          1     ...       \n",
       "2          9      2002  41711    Diesel  90          1     ...       \n",
       "3          7      2002  48000    Diesel  90          0     ...       \n",
       "4          3      2002  38500    Diesel  90          0     ...       \n",
       "\n",
       "  Powered_Windows  Power_Steering  Radio  Mistlamps  Sport_Model  \\\n",
       "0               1               1      0          0            0   \n",
       "1               0               1      0          0            0   \n",
       "2               0               1      0          0            0   \n",
       "3               0               1      0          0            0   \n",
       "4               1               1      0          1            0   \n",
       "\n",
       "   Backseat_Divider  Metallic_Rim  Radio_cassette  Tow_Bar  Validation  \n",
       "0                 1             0               0        0  Validation  \n",
       "1                 1             0               0        0  Validation  \n",
       "2                 1             0               0        0    Training  \n",
       "3                 1             0               0        0    Training  \n",
       "4                 1             0               0        0  Validation  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyota = pd.read_csv('ToyotaCorolla.csv',sep=',',header=0)\n",
    "toyota.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  718 CV:  430 Test:  288\n"
     ]
    }
   ],
   "source": [
    "predictors = ['Age_08_04','KM','Fuel_Type','HP','Automatic','Doors','Quarterly_Tax','Mfg_Guarantee',\n",
    "              'Guarantee_Period','Airco','Automatic_airco','CD_Player','Powered_Windows','Sport_Model','Tow_Bar']\n",
    "predicted = ['Price']\n",
    "train_X,cv_X,train_Y,cv_Y = sklearn.cross_validation.train_test_split(toyota[predictors],toyota[predicted],test_size=0.5)\n",
    "cv_X,test_X,cv_Y,test_Y = sklearn.cross_validation.train_test_split(cv_X,cv_Y,test_size=0.4)\n",
    "print \"Train: \",len(train_Y),\"CV: \",len(cv_Y),\"Test: \",len(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Id\n",
      "Model\n",
      "Price\n",
      "Age_08_04\n",
      "Mfg_Month\n",
      "Mfg_Year\n",
      "KM\n",
      "Fuel_Type\n",
      "HP\n",
      "Met_Color\n",
      "Color\n",
      "Automatic\n",
      "CC\n",
      "Doors\n",
      "Cylinders\n",
      "Gears\n",
      "Quarterly_Tax\n",
      "Weight\n",
      "Mfg_Guarantee\n",
      "BOVAG_Guarantee\n",
      "Guarantee_Period\n",
      "ABS\n",
      "Airbag_1\n",
      "Airbag_2\n",
      "Airco\n",
      "Automatic_airco\n",
      "Boardcomputer\n",
      "CD_Player\n",
      "Central_Lock\n",
      "Powered_Windows\n",
      "Power_Steering\n",
      "Radio\n",
      "Mistlamps\n",
      "Sport_Model\n",
      "Backseat_Divider\n",
      "Metallic_Rim\n",
      "Radio_cassette\n",
      "Tow_Bar\n",
      "Validation\n"
     ]
    }
   ],
   "source": [
    "for col in toyota.columns.values: print col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ï»¿Id                  int64\n",
       "Model               object\n",
       "Price                int64\n",
       "Age_08_04            int64\n",
       "Mfg_Month            int64\n",
       "Mfg_Year             int64\n",
       "KM                   int64\n",
       "Fuel_Type           object\n",
       "HP                   int64\n",
       "Met_Color            int64\n",
       "Color               object\n",
       "Automatic            int64\n",
       "CC                   int64\n",
       "Doors                int64\n",
       "Cylinders            int64\n",
       "Gears                int64\n",
       "Quarterly_Tax        int64\n",
       "Weight               int64\n",
       "Mfg_Guarantee        int64\n",
       "BOVAG_Guarantee      int64\n",
       "Guarantee_Period     int64\n",
       "ABS                  int64\n",
       "Airbag_1             int64\n",
       "Airbag_2             int64\n",
       "Airco                int64\n",
       "Automatic_airco      int64\n",
       "Boardcomputer        int64\n",
       "CD_Player            int64\n",
       "Central_Lock         int64\n",
       "Powered_Windows      int64\n",
       "Power_Steering       int64\n",
       "Radio                int64\n",
       "Mistlamps            int64\n",
       "Sport_Model          int64\n",
       "Backseat_Divider     int64\n",
       "Metallic_Rim         int64\n",
       "Radio_cassette       int64\n",
       "Tow_Bar              int64\n",
       "Validation          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyota.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: Petrol",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-d09fba5faf98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#the minimum number of samples for a leaf is\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#automatically set to 1 here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Jonathan\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1030\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jonathan\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jonathan\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    380\u001b[0m                                       force_all_finite)\n\u001b[0;32m    381\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: Petrol"
     ]
    }
   ],
   "source": [
    "toyota.Fuel_Type = sklearn.preprocessing.LabelEncoder().fit_transform(toyota.Fuel_Type)\n",
    "\n",
    "model = sklearn.tree.DecisionTreeRegressor() #the minimum number of samples for a leaf is \n",
    "#automatically set to 1 here\n",
    "model = model.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Intuitively, as we make more splits, you are going to see an improvement in the training, validaiton, and test sets. However, over time, since the splits are being done with respect to the training data, we will notice improvements in RSquare and RMSE initially for all 3. But, as the tree starts to overfit the training data, we notice that the improvements reverse and start to hurt the accuracy of the model given that the model is not being trained on the held out examples in the cross validation or test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## it says split 1, double check to make sure you did that right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.3 (a) ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"\\nTraining R^2: \",model.score(train_X,train_Y)\n",
    "pred_train = model.predict(train_X)\n",
    "print \"Training RMSE: \",np.sqrt(sklearn.metrics.mean_squared_error(train_Y,pred_train))\n",
    "\n",
    "print \"Cross Validation R^2: \",model.score(cv_X,cv_Y)\n",
    "pred_cv = model.predict(cv_X)\n",
    "print \"Cross Validation RMSE: \",np.sqrt(sklearn.metrics.mean_squared_error(cv_Y,pred_cv))\n",
    "\n",
    "print \"Test R^2: \",model.score(test_X,test_Y)\n",
    "pred_test = model.predict(test_X)\n",
    "print \"Test RMSE: \",np.sqrt(sklearn.metrics.mean_squared_error(test_Y,pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree gets to the point where there is one value in each bucket. So it makes sense that the RMSE and R^2 is perfect because the tree is overfit at this point. So the test set performance is wildly different. The validation set is a lot closer to the test set because the model has not seen the validation set either and the tree has not been pruned using the validation set. So, the error is very similar to the test R^2 and RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.3 (a) iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(predictors)):\n",
    "    print sorted(zip(predictors,model.feature_importances_),\n",
    "                 key = lambda t: t[1],reverse=True)[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.3 (a) iv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params ={'model__max_depth' : range(2,20),\n",
    "         'model__min_samples_leaf': range(2,10),\n",
    "        'model__min_impurity_split' : [1e-7,1e-6,1e-5,1e-4,1e-3]}\n",
    "tree2 = sklearn.tree.DecisionTreeRegressor()\n",
    "pipe = sklearn.pipeline.Pipeline([('model',tree2)])#,('cv',sklearn.model_selection.cross_val_score())])\n",
    "search = sklearn.grid_search.GridSearchCV(pipe,params)\n",
    "search.fit(train_X,train_Y)\n",
    "print search.score(train_X,train_Y)\n",
    "print search.score(cv_X,cv_Y)\n",
    "print search.score(test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# call in rpy2 and prune trees in R to show output\n",
    "\n",
    "So a potential alternative is to run a gridsearch that seeks to maximize the cross validation score based on varying max_depth or max_leaf_node or min split size. Then, have that model returned. Since sklearn does not support pruning. \n",
    "\n",
    "Pruning is a technique in machine learning that reduces the size of decision trees by removing sections of the tree that provide little power to classify instances. Pruning reduces the complexity of the final classifier, and hence improves predictive accuracy by the reduction of overfitting.\n",
    "\n",
    "So something that we could also look at is the min_impurity variable which is something we could set. If the impurity is bad, then we know that the predictive ability is bad and instead of doing this in top-down AND then bottom-up sequence, we could simply does this on the way as we go top-down in decision tree creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.3 (a) v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.3 (a) vi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.3 (a) vii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
